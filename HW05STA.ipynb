{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a13f4283",
   "metadata": {},
   "source": [
    "# A\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b3776b",
   "metadata": {},
   "source": [
    "*hypothesis*:\n",
    "It is a statement or prediction about the relationship between variables.It is served as the foundation of the science research and analysis.Basically ther are two kinds of hypothesis ,null and alternative.The former assume that there are no relatonship between variables,the difference of the variables is based on random chance ,the latter assume that there are exact relationship between variables,aiming to find evidents to support the hypothesis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b887b09b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0af8fffd",
   "metadata": {},
   "source": [
    "# 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737bfeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "The key factor that distinguishes ideas that can be tested statistically from those that cannot is falsifiability. For an idea to be testable, it must be structured in a way that allows for the possibility of being proven false through empirical evidence. This means that there should be a clear way to collect data and analyze it to either support or reject the idea.\n",
    "\n",
    "\n",
    "in my opinion : a good null hypothesis is that it should be clear which means the relationship is precise and testable and falsifiable which means it can proved to be false.\n",
    "    \n",
    "    \n",
    "\n",
    "    null hypothesis:assume that there are no relatonship between variables,the difference of the variables is based on random chance .Alternative hypothesis:assume that there are exact relationship between variables,aiming to find evidents to support the hypothesis. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca94a075",
   "metadata": {},
   "source": [
    "# 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e20ef6d",
   "metadata": {},
   "source": [
    "The sentence means that when we perform hypothesis tests in statistics, we're aiming to learn about the **population mean** (\\( \\mu \\)), not just the average from our sample (\\( \\bar{x} \\)). \n",
    "\n",
    "**( x_i \\)**: Individual data points in the sample.\n",
    "**\\($ bar{x} $)**: The average of those individual data points (the sample mean).\n",
    "**\\( $mu $)**: The average of the entire population.\n",
    "**\\( $mu_0 $)**: A specific value of the population mean we are testing against.\n",
    "\n",
    " our goal is to make inferences about the entire population, not just the sample we collected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db652825",
   "metadata": {},
   "source": [
    "# 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06bde274",
   "metadata": {},
   "source": [
    "*Null hypothesis* heips us to assess the significance of our findings objectively.This method provides a structured way to draw conclusions based on statistical evidence.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3300a1f",
   "metadata": {},
   "source": [
    "# 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39fe452",
   "metadata": {},
   "source": [
    "**p-value**: The p-value is a statistical measure that helps us determine the strength of evidence against the null hypothesis.It tells us the probability of observing data as extreme as what we actually observed, given that the null hypothesis is true.\n",
    "\n",
    "**Null Hypothesis**: The null hypothesis is a statement that suggests there is no effect or no relationship in the variables.\n",
    "\n",
    "A smaller p-value provides strong evidence against the null hypothesis. It suggests that the null hypothesis is less likely to be true because the observed data would be very unlikely to occur if the null hypothesis were accurate, indicating that there is something significant happening in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed90959b",
   "metadata": {},
   "source": [
    "# 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa8908e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Simulation parameters\n",
    "num_simulations = 10000  # Number of simulated trials\n",
    "num_couples = 124        # Number of couples observed\n",
    "observed_right_tilts = 80  # Observed right tilts in original data\n",
    "prob_right_tilt = 0.5    # Probability of tilting right under H₀\n",
    "\n",
    "# Simulate trials under the null hypothesis\n",
    "simulations = np.random.binomial(n=num_couples, p=prob_right_tilt, size=num_simulations)\n",
    "\n",
    "# Calculate the p-value: proportion of simulations with right tilts >= observed_right_tilts\n",
    "p_value = np.sum(simulations >= observed_right_tilts) / num_simulations\n",
    "p_value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5e8f39",
   "metadata": {},
   "source": [
    "# 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0848bd88",
   "metadata": {},
   "source": [
    "A smaller p-value cannot definitively prove the null hypothesis is false, however, it only suggests how unlikely the observed data would be if the null hypothesis were true.  p-values provide evidence against the null hypothesis, but they don’t “prove” anything absolutely; they measure the likelihood of observing the data under an assumption.\n",
    "In the case of determining Fido’s innocence or guilt, a p-value doesn’t provide absolute proof either. A very low p-value suggests that the observed evidence is inconsistent with Fido's innocence if we assume it , but it can’t prove guilt. Similarly, a high p-value doesn’t prove innocence; it just indicates insufficient proof against it.\n",
    "To summarize, no p-value can definitively prove innocence or guilt. P-values only measure evidence strength."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf3b556",
   "metadata": {},
   "source": [
    "# 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38db7495",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import ttest_1samp\n",
    "\n",
    "# Original Data\n",
    "patient_data = pd.DataFrame({\n",
    "    \"PatientID\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "    \"Age\": [45, 34, 29, 52, 37, 41, 33, 48, 26, 39],\n",
    "    \"Gender\": [\"M\", \"F\", \"M\", \"F\", \"M\", \"F\", \"M\", \"F\", \"M\", \"F\"],\n",
    "    \"InitialHealthScore\": [84, 78, 83, 81, 81, 80, 79, 85, 76, 83],\n",
    "    \"FinalHealthScore\": [86, 86, 80, 86, 84, 86, 86, 82, 83, 84]\n",
    "})\n",
    "\n",
    "# Calculate the health score change\n",
    "patient_data['HealthScoreChange'] = patient_data['FinalHealthScore'] - patient_data['InitialHealthScore']\n",
    "\n",
    "# Perform one-sided t-test to see if the health score has increased\n",
    "# Null hypothesis (H0): Mean change <= 0\n",
    "# Alternative hypothesis (H1): Mean change > 0\n",
    "t_stat, p_value_two_tailed = ttest_1samp(patient_data['HealthScoreChange'], 0)\n",
    "\n",
    "# Convert the two-tailed p-value to one-tailed by halving it (only if t_stat is positive)\n",
    "if t_stat > 0:\n",
    "    p_value_one_tailed = p_value_two_tailed / 2\n",
    "else:\n",
    "    p_value_one_tailed = 1  # if t_stat is negative, one-tailed test does not support increase hypothesis\n",
    "\n",
    "print(f\"One-tailed p-value: {p_value_one_tailed}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d482bb",
   "metadata": {},
   "source": [
    "**Explanation of the Adjustment**\n",
    "t-test Calculation: We use ttest_1samp to test if the average HealthScoreChange is greater than zero.\n",
    "One-sided p-value: We divide the two-sided p-value by 2 to get the one-sided p-value, only if the test statistic t_stat is positive, indicating a mean increase. If t_stat is negative, it would not support an increase, and we set the p-value to 1 to reflect that.\n",
    "This code now tests specifically for a significant increase in health scores (one-tailed test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f510a8",
   "metadata": {},
   "source": [
    "Switching from a two-sided to a one-sided hypothesis test changes the interpretation in the following ways:\n",
    "\n",
    "1. **Direction of the Test**:\n",
    "   - In a **two-sided test**, the hypothesis considers *any significant change*, either an increase or a decrease in health scores. This tests the hypothesis:  \n",
    "     - **Null Hypothesis (H₀)**: There is no change (mean change = 0).\n",
    "     - **Alternative Hypothesis (H₁)**: There is a change (mean change ≠ 0).\n",
    "   - In a **one-sided test**, we test specifically for a *positive change* in health scores, ignoring the possibility of a decrease. This tests the hypothesis:\n",
    "     - **Null Hypothesis (H₀)**: There is no increase in health score or it has decreased (mean change ≤ 0).\n",
    "     - **Alternative Hypothesis (H₁)**: There is an increase in health score (mean change > 0).\n",
    "\n",
    "2. **Interpretation of Results**:\n",
    "   - In the **two-sided test**, a significant result indicates that the health scores changed significantly in *either direction*, but it doesn't specify which one.\n",
    "   - In the **one-sided test**, a significant result specifically supports that the health scores increased after treatment, aligning with a more directional hypothesis.\n",
    "\n",
    "3. **Expectation of p-value**:\n",
    "   - The **one-sided test** has a lower p-value threshold for significance in a specific direction. By halving the range of possible outcomes, it allows the same observed data to yield a smaller p-value if the effect aligns with the hypothesized direction (e.g., an increase in scores).\n",
    "\n",
    "Overall, a one-sided test provides stronger evidence for a hypothesized direction (an increase here) but also limits our test to only detecting effects in that direction. If scores had decreased, the one-sided test would not recognize it as significant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf8c17d",
   "metadata": {},
   "source": [
    "Yes, in general, we should expect the p-value to be smaller in a one-tailed test compared to a two-tailed test—*if* the observed effect aligns with the direction specified by the one-tailed hypothesis. This happens because:\n",
    "\n",
    "1. **Probability Allocation**:\n",
    "   - In a **two-tailed test**, the p-value considers extreme values in both directions of the distribution (positive and negative deviations from the mean). This doubles the range of values that could lead to a significant result, which effectively \"splits\" the p-value between the two tails of the distribution.\n",
    "   - In a **one-tailed test**, the p-value focuses on only one end of the distribution (e.g., only looking for increases). This effectively halves the probability range, making it easier to achieve a smaller p-value for a given effect size in the hypothesized direction.\n",
    "\n",
    "2. **One-Tailed Test Requirement**:\n",
    "   - If the observed effect goes in the expected direction (e.g., an increase if we’re testing for an increase), the one-tailed p-value will be smaller since it doesn’t need to account for deviations in the opposite direction.\n",
    "   - However, if the observed effect goes in the opposite direction (e.g., a decrease when testing for an increase), the one-tailed p-value will be higher because it’s essentially saying the effect does not support the hypothesis.\n",
    "\n",
    "So, with aligned data, **the p-value in a one-tailed test is typically smaller than in a two-tailed test**, reflecting a more focused hypothesis about the direction of the effect."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f94ad2",
   "metadata": {},
   "source": [
    "# 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3ea400",
   "metadata": {},
   "source": [
    "\n",
    "#### **1. Problem Introduction**\n",
    "\n",
    "The experiment here follows the model of Fisher's original tea experiment but adapts it to a different population. In Fisher's scenario, Dr. Bristol was asked to identify whether milk or tea was poured first, claiming she could distinguish the difference, which Fisher tested statistically. In our experiment, we sample STA130 students to determine whether they can detect this same difference. We’ll analyze whether the 49 out of 80 students who correctly guessed the pouring order could be due to random chance, using hypothesis testing.\n",
    "\n",
    "#### **2. Relationship to Fisher's Original Experiment**\n",
    "\n",
    "The original experiment had a small sample size (8 cups) and tested a personalized skill Dr. Bristol claimed to have. In contrast, this experiment uses a larger sample (80 students), without specific expertise. This makes the parameter more abstract, as students may or may not have any inherent sensitivity to the difference in pouring order.\n",
    "\n",
    "---\n",
    "\n",
    "#### **3. Null and Alternative Hypotheses**\n",
    "\n",
    "- **Null Hypothesis (H₀):** Students are guessing the pouring order at random, so they are correct with a probability of 0.5.\n",
    "  - **Formal Statement:** \\( H_0: p = 0.5 \\)\n",
    "  - **Informal Statement:** Under the null hypothesis, we assume students have no real ability to discern the pouring order and are only correct half the time by chance.\n",
    "\n",
    "- **Alternative Hypothesis (H₁):** Students have some ability to detect the difference in pouring order, reflected in a probability of success greater than 0.5.\n",
    "  - **Formal Statement:** \\( H_1: p > 0.5 \\)\n",
    "\n",
    "---\n",
    "\n",
    "#### **4. Quantitative Analysis**\n",
    "\n",
    "Given that 49 out of 80 students were correct, our observed proportion \\( \\hat{p} = \\frac{49}{80} = 0.6125 \\).\n",
    "\n",
    "1. **Assumption Check**: Since we’re testing against a hypothesized population proportion of 0.5, we can use a one-sample proportion test.\n",
    "2. **Significance Test**: We’ll use a z-test for proportions to determine if the observed success rate significantly differs from 0.5.\n",
    "   - **Formula for Test Statistic (z)**:\n",
    "     \\[\n",
    "     z = \\frac{\\hat{p} - p_0}{\\sqrt{\\frac{p_0 (1 - p_0)}{n}}}\n",
    "     \\]\n",
    "   - Where:\n",
    "     - \\( \\hat{p} = 0.6125 \\)\n",
    "     - \\( p_0 = 0.5 \\)\n",
    "     - \\( n = 80 \\)\n",
    "\n",
    "3. **Methodology and Reproducibility**: We’ll perform the z-test in Python and calculate the p-value to assess our hypothesis. Setting `np.random.seed()` will make the results reproducible.\n",
    "\n",
    "#### **5. Code Implementation**\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Sample information\n",
    "n = 80            # Sample size\n",
    "p_hat = 49 / 80   # Observed proportion\n",
    "p_0 = 0.5         # Null hypothesis proportion\n",
    "\n",
    "# Calculate the z-score\n",
    "z = (p_hat - p_0) / np.sqrt(p_0 * (1 - p_0) / n)\n",
    "\n",
    "# Calculate the p-value (one-tailed test)\n",
    "p_value = 1 - stats.norm.cdf(z)\n",
    "\n",
    "print(f\"Test Statistic (z): {z:.4f}\")\n",
    "print(f\"P-value: {p_value:.4f}\")\n",
    "```\n",
    "\n",
    "#### **6. Interpretation and Discussion of Results**\n",
    "\n",
    "- **Test Statistic**: The test statistic \\( z \\) provides a measure of how far the observed sample proportion is from the null hypothesis proportion (0.5), standardized by the sample size.\n",
    "- **P-value**: The p-value quantifies the probability of observing a result as extreme as or more extreme than 0.6125 under the null hypothesis. If the p-value is below our significance level (commonly 0.05), we would reject \\( H_0 \\) and conclude that students likely have some ability to distinguish pouring order.\n",
    "\n",
    "#### **7. Findings**\n",
    "\n",
    "- **Interpretation**: If the p-value is small (e.g., < 0.05), we conclude that students are not guessing randomly and likely have some ability to discern the order.\n",
    "- **Visual Representation (Optional)**: A histogram of a simulated sampling distribution under \\( H_0 \\) could visualize how unusual a 0.6125 proportion is.\n",
    "\n",
    "---\n",
    "\n",
    "#### **8. Conclusion**\n",
    "\n",
    "Based on the results of the statistical test, we either:\n",
    "- Reject \\( H_0 \\), suggesting that students in STA130 are better than random guessing at detecting the pouring order, or\n",
    "- Fail to reject \\( H_0 \\), concluding that the students’ ability to guess correctly aligns with random chance.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68527851",
   "metadata": {},
   "source": [
    "# 9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a45b09d",
   "metadata": {},
   "source": [
    "yes it really help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a56f087",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2d1d31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58273c4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726b1583",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c0e571",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3954c4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd15d55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5a252db1",
   "metadata": {},
   "source": [
    " chat history :https://chatgpt.com/share/670e0c19-a8a4-8003-b6c4-1f734906d12f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8cd5e4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
